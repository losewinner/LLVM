; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx942 < %s | FileCheck %s

; Check that simple conditional memory accesses that are guarded by likely
; varying conditions are not lowered with an s_cbranch_execz to bypass them.

declare i32 @llvm.amdgcn.workitem.id.x()
declare i32 @llvm.amdgcn.workitem.id.y()

define amdgpu_kernel void @cond_ops(ptr addrspace(1) inreg %x, ptr addrspace(1) inreg %y) !reqd_work_group_size !0 {
; CHECK-LABEL: cond_ops:
; CHECK:         s_trap 2 ; Kernarg preload header. Trap with incompatible firmware that doesn't support preloading kernel arguments.
; CHECK-NEXT:    .fill 63, 4, 0xbf800000 ; s_nop 0
; CHECK-NEXT:  ; %bb.0: ; %entry
; CHECK-NEXT:    v_and_b32_e32 v1, 0x3ff, v0
; CHECK-NEXT:    v_bfe_u32 v0, v0, 10, 10
; CHECK-NEXT:    v_lshl_or_b32 v5, v0, 6, v1
; CHECK-NEXT:    v_lshrrev_b32_e32 v0, 4, v5
; CHECK-NEXT:    v_cmp_gt_u32_e32 vcc, 15, v0
; CHECK-NEXT:    v_mov_b32_e32 v0, 0
; CHECK-NEXT:    v_lshlrev_b32_e32 v4, 4, v5
; CHECK-NEXT:    v_mov_b32_e32 v1, 0
; CHECK-NEXT:    v_mov_b32_e32 v2, 0
; CHECK-NEXT:    v_mov_b32_e32 v3, 0
; CHECK-NEXT:    s_and_saveexec_b64 s[0:1], vcc
; CHECK-NEXT:  ; %bb.1: ; %do.load
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v4, s[8:9]
; CHECK-NEXT:  ; %bb.2: ; %post.load
; CHECK-NEXT:    s_or_b64 exec, exec, s[0:1]
; CHECK-NEXT:    v_and_b32_e32 v5, 15, v5
; CHECK-NEXT:    v_cmp_gt_u32_e32 vcc, 15, v5
; CHECK-NEXT:    s_and_saveexec_b64 s[0:1], vcc
; CHECK-NEXT:    s_cbranch_execz .LBB0_4
; CHECK-NEXT:  ; %bb.3: ; %do.store
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v4, v[0:3], s[10:11]
; CHECK-NEXT:  .LBB0_4: ; %exit
; CHECK-NEXT:    s_endpgm
entry:
  %tid.x = tail call range(i32 0, 64) i32 @llvm.amdgcn.workitem.id.x()
  %tid.y = tail call range(i32 0, 4) i32 @llvm.amdgcn.workitem.id.y()
  %tid.y.shift = shl nuw nsw i32 %tid.y, 6
  %tid = or disjoint i32 %tid.x, %tid.y.shift
  %k = lshr i32 %tid, 4
  %j = and i32 %tid, 15
  %load.cond = icmp ult i32 %k, 15
  %tid.ext = zext nneg i32 %tid to i64
  %my.x = getelementptr <4 x float>, ptr addrspace(1) %x, i64 %tid.ext
  br i1 %load.cond, label %do.load, label %post.load
do.load:
  %loaded = load <4 x float>, ptr addrspace(1) %my.x
  br label %post.load
post.load:
  %maybe.loaded = phi <4 x float> [ %loaded, %do.load ], [ zeroinitializer, %entry ]
  %my.y = getelementptr <4 x float>, ptr addrspace(1) %y, i64 %tid.ext
  %store.cond = icmp ult i32 %j, 15
  br i1 %store.cond, label %do.store, label %exit
do.store:
  store <4 x float> %maybe.loaded, ptr addrspace(1) %my.y
  br label %exit
exit:
  ret void
}

!0 = !{i32 64, i32 4, i32 1}
