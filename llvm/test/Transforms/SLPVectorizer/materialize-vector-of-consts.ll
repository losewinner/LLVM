; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: %if aarch64-registered-target %{ opt -passes=slp-vectorizer -mtriple=aarch64 -S %s | FileCheck %s %}

define <2 x float> @v2f32_diff_consts(float %a, float %b)
; CHECK-LABEL: define <2 x float> @v2f32_diff_consts(
; CHECK-SAME: float [[A:%.*]], float [[B:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = fmul float [[A]], 2.200000e+01
; CHECK-NEXT:    [[TMP2:%.*]] = fmul float [[B]], 2.300000e+01
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x float> poison, float [[TMP1]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x float> [[TMP4]], float [[TMP2]], i32 1
; CHECK-NEXT:    ret <2 x float> [[TMP3]]
;
{
  %1 = fmul float %a, 22.0
  %2 = fmul float %b, 23.0
  %3 = insertelement <2 x float> poison, float %1, i32 0
  %4 = insertelement <2 x float> %3, float %2, i32 1
  ret <2 x float> %4
}

define <2 x float> @v2f32_const_splat(float %a, float %b)
; CHECK-LABEL: define <2 x float> @v2f32_const_splat(
; CHECK-SAME: float [[A:%.*]], float [[B:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x float> poison, float [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x float> [[TMP1]], float [[B]], i32 1
; CHECK-NEXT:    [[TMP3:%.*]] = fmul <2 x float> [[TMP2]], splat (float 2.200000e+01)
; CHECK-NEXT:    ret <2 x float> [[TMP3]]
;
{
  %1 = fmul float %a, 22.0
  %2 = fmul float %b, 22.0
  %3 = insertelement <2 x float> poison, float %1, i32 0
  %4 = insertelement <2 x float> %3, float %2, i32 1
  ret <2 x float> %4
}

; This needs type legalization since <4 x double> won't fit into a single register.
; So, we bail out for now while calculating the cost of vector of constants.
define <4 x double> @v4f64_illegal_type(double %a, double %b, double %c, double %d)
; CHECK-LABEL: define <4 x double> @v4f64_illegal_type(
; CHECK-SAME: double [[A:%.*]], double [[B:%.*]], double [[C:%.*]], double [[D:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <4 x double> poison, double [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x double> [[TMP1]], double [[B]], i32 1
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x double> [[TMP2]], double [[C]], i32 2
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <4 x double> [[TMP3]], double [[D]], i32 3
; CHECK-NEXT:    [[TMP5:%.*]] = fmul <4 x double> [[TMP4]], <double 2.100000e+01, double 2.200000e+01, double 2.300000e+01, double 2.400000e+01>
; CHECK-NEXT:    ret <4 x double> [[TMP5]]
;
{
  %1 = fmul double %a, 21.0
  %2 = fmul double %b, 22.0
  %3 = fmul double %c, 23.0
  %4 = fmul double %d, 24.0
  %5 = insertelement <4 x double> poison, double %1, i32 0
  %6 = insertelement <4 x double> %5, double %2, i32 1
  %7 = insertelement <4 x double> %6, double %3, i32 2
  %8 = insertelement <4 x double> %7, double %4, i32 3
  ret <4 x double> %8
}

; Here, we have 2 SLP trees. Both calculate the cost of <2 x double><double 21.0, double 22.0>
; seperately/individually and hence, both the trees are not vectorized. But, in terms of codegen,
; this const vector needs to be realized only once and hence, considering the cost of const
; vector twice is inappropriate.
; But, suprisingly, llvm-mca for -mtriple=aarch64 shows scalar version to be slightly better.
define <2 x double> @v2f64_dup_const_vector_case1(double %a, double %b, double %c, double %d)
; CHECK-LABEL: define <2 x double> @v2f64_dup_const_vector_case1(
; CHECK-SAME: double [[A:%.*]], double [[B:%.*]], double [[C:%.*]], double [[D:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = fmul double [[A]], 2.100000e+01
; CHECK-NEXT:    [[TMP2:%.*]] = fmul double [[B]], 2.200000e+01
; CHECK-NEXT:    [[TMP8:%.*]] = fmul double [[C]], 2.100000e+01
; CHECK-NEXT:    [[TMP4:%.*]] = fmul double [[D]], 2.200000e+01
; CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> poison, double [[TMP1]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x double> [[TMP5]], double [[TMP2]], i32 1
; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <2 x double> poison, double [[TMP8]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x double> [[TMP9]], double [[TMP4]], i32 1
; CHECK-NEXT:    [[TMP7:%.*]] = fadd <2 x double> [[TMP3]], [[TMP6]]
; CHECK-NEXT:    ret <2 x double> [[TMP7]]
;
{
  %1 = fmul double %a, 21.0
  %2 = fmul double %b, 22.0
  %3 = fmul double %c, 21.0
  %4 = fmul double %d, 22.0
  %5 = insertelement <2 x double> poison, double %1, i32 0
  %6 = insertelement <2 x double> %5, double %2, i32 1
  %7 = insertelement <2 x double> poison, double %3, i32 0
  %8 = insertelement <2 x double> %7, double %4, i32 1
  %9 = fadd <2 x double> %6, %8
  ret <2 x double> %9
}

; llvm-mca for -mtriple=aarch64 shows scalar version to be only slightly better.
define <2 x double> @v2f64_dup_const_vector_case2(double %a, double %b, double %c, double %d)
; CHECK-LABEL: define <2 x double> @v2f64_dup_const_vector_case2(
; CHECK-SAME: double [[A:%.*]], double [[B:%.*]], double [[C:%.*]], double [[D:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x double> poison, double [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> [[TMP1]], double [[B]], i32 1
; CHECK-NEXT:    [[TMP3:%.*]] = fmul <2 x double> [[TMP2]], <double 2.100000e+01, double 2.200000e+01>
; CHECK-NEXT:    [[TMP4:%.*]] = fadd <2 x double> [[TMP3]], <double 2.100000e+01, double 2.200000e+01>
; CHECK-NEXT:    ret <2 x double> [[TMP4]]
;
{
  %1 = fmul double %a, 21.0
  %2 = fmul double %b, 22.0
  %3 = fadd double %1, 21.0
  %4 = fadd double %2, 22.0
  %5 = insertelement <2 x double> poison, double %3, i32 0
  %6 = insertelement <2 x double> %5, double %4, i32 1
  ret <2 x double> %6
}
